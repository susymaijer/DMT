{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import ndcg_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.read_csv(\"data/dummy/train.csv\")\n",
    "x_test = pd.read_csv(\"data/dummy/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x.target.squeeze()\n",
    "x.drop(['target', 'click_bool', 'booking_bool', 'position', 'date_time'], axis=1, inplace=True) \n",
    "## TODO: gross_bookings_usd is already dropped, not right but okay\n",
    "## TODO: date_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = x_test.target.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndcg(rel_true, rel_pred, p=None, form=\"linear\"):\n",
    "    \"\"\" Returns normalized Discounted Cumulative Gain\n",
    "    Args:\n",
    "        rel_true (1-D Array): relevance lists for particular user, (n_songs,)\n",
    "        rel_pred (1-D Array): predicted relevance lists, (n_pred,)\n",
    "        p (int): particular rank position\n",
    "        form (string): two types of nDCG formula, 'linear' or 'exponential'\n",
    "    Returns:\n",
    "        ndcg (float): normalized discounted cumulative gain score [0, 1]\n",
    "    \"\"\"\n",
    "    rel_true = np.sort(rel_true)[::-1]\n",
    "    p = min(len(rel_true), min(len(rel_pred), p))\n",
    "    discount = 1 / (np.log2(np.arange(p) + 2))\n",
    "\n",
    "    if form == \"linear\":\n",
    "        idcg = np.sum(rel_true[:p] * discount)\n",
    "        dcg = np.sum(rel_pred[:p] * discount)\n",
    "    elif form == \"exponential\" or form == \"exp\":\n",
    "        idcg = np.sum([2**x - 1 for x in rel_true[:p]] * discount)\n",
    "        dcg = np.sum([2**x - 1 for x in rel_pred[:p]] * discount)\n",
    "    else:\n",
    "        raise ValueError(\"Only supported for two formula, 'linear' or 'exp'\")\n",
    "\n",
    "    return dcg / idcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported format string passed to function.__format__",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-898a210dda59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGradientBoostingClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mndcg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m    439\u001b[0m             \u001b[0mX_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36m_check_params\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    234\u001b[0m         if (self.loss not in self._SUPPORTED_LOSS\n\u001b[1;32m    235\u001b[0m                 or self.loss not in _gb_losses.LOSS_FUNCTIONS):\n\u001b[0;32m--> 236\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loss '{0:s}' not supported. \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'deviance'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported format string passed to function.__format__"
     ]
    }
   ],
   "source": [
    "import lightgbm\n",
    "\n",
    "# default lightgbm model with sklearn api\n",
    "gbm = lightgbm.LGBMRegressor() \n",
    "\n",
    "# updating objective function to custom\n",
    "# default is \"regression\"\n",
    "# also adding metrics to check different scores\n",
    "gbm.set_params(**{'objective': ndcg}, metrics = [\"mse\"])\n",
    "\n",
    "# fitting model \n",
    "gbm.fit(\n",
    "    x,\n",
    "    y,\n",
    "    eval_set=[(x_test, y_test)],\n",
    "    eval_metric=ndcg,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "y_pred = gbm.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
